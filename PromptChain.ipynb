{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-16T10:12:18.718144Z",
     "start_time": "2025-10-16T10:12:18.585189Z"
    }
   },
   "source": "@file:DependsOn(\"ai.koog:koog-agents-jvm:0.5.0\")",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T10:12:19.679044Z",
     "start_time": "2025-10-16T10:12:19.484406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ai.koog.prompt.executor.clients.anthropic.AnthropicLLMClient\n",
    "import ai.koog.prompt.executor.llms.all.simpleAnthropicExecutor\n",
    "import ai.koog.prompt.executor.ollama.client.OllamaClient\n",
    "import ai.koog.prompt.executor.llms.all.simpleOllamaAIExecutor\n",
    "import ai.koog.prompt.llm.LLMCapability\n",
    "import ai.koog.prompt.llm.LLMProvider\n",
    "import ai.koog.prompt.llm.LLModel\n",
    "\n",
    "val ollama = OllamaClient()\n",
    "val anthropic = AnthropicLLMClient(System.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "val executor = simpleAnthropicExecutor(System.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "val GptOss = LLModel(\n",
    "    provider = LLMProvider.Ollama,\n",
    "    id = \"gpt-oss:20b\",\n",
    "    capabilities = listOf(\n",
    "        LLMCapability.Temperature,\n",
    "        LLMCapability.Schema.JSON.Standard,\n",
    "        LLMCapability.Tools,\n",
    "        LLMCapability.OpenAIEndpoint.Completions,\n",
    "        LLMCapability.OpenAIEndpoint.Responses,\n",
    "    ),\n",
    "    contextLength = 128_000,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:29:56.585939Z",
     "start_time": "2025-10-16T14:29:56.559056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.io.File\n",
    "\n",
    "val files = File(\".\").listFiles()\n",
    "files"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[./Chat2.ipynb, ./slides.md, ./PromptChain.ipynb, ./.DS_Store, ./test, ./slidev.iml, ./node_modules, ./setup, ./README.md, ./Example.ipynb, ./test.html, ./.gitignore, ./package-lock.json, ./package.json, ./slides3.md, ./Agent.ipynb, ./Dark.icls, ./kotlin-theme, ./slidev.config.ts, ./.git, ./PromptChain2.ipynb, ./assets, ./Chat.ipynb, ./.idea]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:31:08.422815Z",
     "start_time": "2025-10-16T14:30:56.827465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ai.koog.prompt.dsl.prompt\n",
    "import ai.koog.prompt.executor.clients.anthropic.AnthropicModels\n",
    "import ai.koog.prompt.structure.executeStructured\n",
    "import ai.koog.prompt.xml.xml\n",
    "import kotlinx.coroutines.Dispatchers\n",
    "import kotlinx.coroutines.async\n",
    "import kotlinx.coroutines.awaitAll\n",
    "import kotlinx.coroutines.runBlocking\n",
    "\n",
    "val summarised = runBlocking(Dispatchers.Default) {\n",
    "    files\n",
    "        .filter { it.isFile }\n",
    "        .take(5)\n",
    "        .map { file ->\n",
    "            async {\n",
    "                Pair(file.name, executor.execute(prompt(\"summarise\") {\n",
    "                    system {\n",
    "                        +\"Find all relevant project files. Ignore hidden files, git, and configuration related files\"\n",
    "                        +\"If content is irrelevant return an empty string \\\"\\\"\"\n",
    "                    }\n",
    "                    user {\n",
    "                        xml {\n",
    "                            tag(\"content\") {\n",
    "                                +\"${file.readText()}\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }, AnthropicModels.Sonnet_4_5).single().content)\n",
    "            }\n",
    "        }.awaitAll()\n",
    "}\n",
    "summarised"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Chat2.ipynb, \"\"\n",
       "\n",
       "This is a Jupyter notebook file demonstrating the usage of a Kotlin library (koog-agents), not a project source file that would be relevant for project analysis. It contains examples and experiments rather than production code.), (slides.md, This appears to be a presentation about Kotlin, Ktor, and Koog (an AI/LLM framework). The content covers:\n",
       "\n",
       "1. **LLM (Language Learning Models)** - Basics of how LLMs work, tokenization, parameters, and context windows\n",
       "2. **Koog Framework** - Building AI agents with tool calling capabilities in Kotlin\n",
       "3. **Ktor Integration** - Using Koog with Ktor for server-sent events and web applications\n",
       "4. **Kotlin DSL Design** - Creating typesafe domain-specific languages using:\n",
       "   - Lambda with receiver\n",
       "   - Extension functions\n",
       "   - Builder patterns\n",
       "\n",
       "Key topics:\n",
       "- LLM fundamentals (tokenization, parameters, context windows)\n",
       "- AI agents and tool calling workflows\n",
       "- Prompt engineering and chaining\n",
       "- Ktor server configuration and SSE\n",
       "- Kotlin DSL patterns (lambdas, receivers, extension functions)\n",
       "- Practical exercises for building prompt DSLs\n",
       "\n",
       "The presentation uses Slidev (a slide framework) with Kotlin code examples, Mermaid diagrams for visualizing agent workflows, and interactive \"magic-move\" animations to show code progression.), (PromptChain.ipynb, # Koog AI Agents - Project Documentation Generator\n",
       "\n",
       "A meta-demonstration project showcasing the **Koog AI Agents library** for Kotlin, which uses LLMs to automatically analyze and document codebases.\n",
       "\n",
       "## 🎯 Project Overview\n",
       "\n",
       "This project demonstrates how to build an AI-powered documentation generator using Kotlin and the Koog library. It includes both a working Jupyter notebook implementation and a comprehensive Slidev presentation explaining the concepts behind LLMs, DSLs, and prompt engineering.\n",
       "\n",
       "### What It Does\n",
       "\n",
       "The notebook implements an automated documentation pipeline that:\n",
       "1. **Scans** a project directory and filters relevant files\n",
       "2. **Summarizes** each file in parallel using LLM APIs\n",
       "3. **Synthesizes** all summaries into a coherent README.md\n",
       "4. **Demonstrates** meta-programming by documenting itself\n",
       "\n",
       "## 🛠️ Technology Stack\n",
       "\n",
       "- **Kotlin** 2.2.20-Beta2\n",
       "- **Koog Agents JVM** v0.5.0 (ai.koog:koog-agents-jvm)\n",
       "- **Anthropic Claude** Sonnet 4.5 (for production summarization)\n",
       "- **Ollama** (for local LLM experimentation)\n",
       "- **Kotlin Coroutines** (for async/parallel processing)\n",
       "- **Slidev** (for presentation slides)\n",
       "\n",
       "## 📁 Key Components\n",
       "\n",
       "### 1. PromptChain.ipynb\n",
       "The main implementation demonstrating:\n",
       "- **Multi-provider LLM setup** (Anthropic & Ollama)\n",
       "- **Kotlin DSL for prompts** with clean, declarative syntax\n",
       "- **Parallel file processing** using coroutines\n",
       "- **Structured prompt engineering** with XML tags\n",
       "- **Token budget management** (200k token awareness)\n",
       "\n",
       "### 2. slides.md\n",
       "Comprehensive presentation covering:\n",
       "- **LLM fundamentals**: tokenization, context windows\n",
       "- **Koog library architecture** and design principles\n",
       "- **Kotlin DSL patterns**: lambdas with receivers\n",
       "- **Prompt engineering** best practices\n",
       "- **Hands-on exercises** for workshop attendees\n",
       "\n",
       "### 3. Configuration Files\n",
       "- **slidev.config.ts**: Shiki syntax highlighting setup\n",
       "- **setup/main.ts**: Vue component registration for animations\n",
       "- **package.json**: Project dependencies\n",
       "\n",
       "## 🚀 Getting Started\n",
       "\n",
       "### Prerequisites\n",
       "```bash\n",
       "# Install dependencies\n",
       "npm install\n",
       "\n",
       "# Set up API keys\n",
       "export ANTHROPIC_API_KEY=\"your-key-here\"\n",
       "```\n",
       "\n",
       "### Running the Notebook\n",
       "```kotlin\n",
       "// The notebook is self-contained and can be run cell-by-cell\n",
       "// It will analyze the current project and generate documentation\n",
       "```\n",
       "\n",
       "### Viewing the Presentation\n",
       "```bash\n",
       "# Development mode\n",
       "npm run dev\n",
       "\n",
       "# Build for production\n",
       "npm run build\n",
       "\n",
       "# Export to PDF\n",
       "npm run export\n",
       "```\n",
       "\n",
       "## 💡 Key Features Demonstrated\n",
       "\n",
       "### 1. Declarative Prompt DSL\n",
       "```kotlin\n",
       "prompt {\n",
       "    system { +\"You are a code analysis expert\" }\n",
       "    user {\n",
       "        tag(\"file\", \"name\" to filename) {\n",
       "            +content\n",
       "        }\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "### 2. Async Processing\n",
       "```kotlin\n",
       "// Process multiple files concurrently\n",
       "val summaries = files.map { file ->\n",
       "    async { summarizeFile(file) }\n",
       "}.awaitAll()\n",
       "```\n",
       "\n",
       "### 3. Multi-Provider Support\n",
       "```kotlin\n",
       "// Switch between providers easily\n",
       "val claude = anthropicClient(model = \"claude-sonnet-4.5\")\n",
       "val local = ollamaClient(model = \"llama3.2\")\n",
       "```\n",
       "\n",
       "## 📚 Learning Resources\n",
       "\n",
       "This project serves as:\n",
       "- **Working example** of Koog library usage\n",
       "- **Educational material** for LLM integration in Kotlin\n",
       "- **Workshop content** for teaching prompt engineering\n",
       "- **Meta-demonstration** of self-documenting code\n",
       "\n",
       "## 🎓 Presentation Topics\n",
       "\n",
       "The included slides cover:\n",
       "1. **Introduction to LLMs**: How they work and their capabilities\n",
       "2. **Tokenization**: Understanding context windows and limits\n",
       "3. **Koog Library**: Design philosophy and API patterns\n",
       "4. **DSL Design**: Kotlin lambdas with receivers explained\n",
       "5. **Prompt Engineering**: Best practices and common pitfalls\n",
       "6. **Hands-on Exercises**: Interactive coding challenges\n",
       "\n",
       "## 🔧 Advanced Usage\n",
       "\n",
       "### Custom Summarization\n",
       "Modify the prompt templates in the notebook to:\n",
       "- Focus on specific aspects (security, performance, architecture)\n",
       "- Generate different documentation formats\n",
       "- Support multiple languages\n",
       "\n",
       "### Local Development\n",
       "Use Ollama for privacy-focused, offline development:\n",
       "```kotlin\n",
       "val localClient = ollamaClient(\n",
       "    baseUrl = \"http://localhost:11434\",\n",
       "    model = \"llama3.2\"\n",
       ")\n",
       "```\n",
       "\n",
       "## 📄 License & Attribution\n",
       "\n",
       "This project demonstrates the Koog AI Agents library. For library documentation and updates, visit the official Koog repository.\n",
       "\n",
       "---\n",
       "\n",
       "**Note**: This README was generated using the very system it documents - a meta-demonstration of AI-assisted documentation generation! 🤖✨), (.DS_Store, I'm looking at what appears to be a binary or corrupted file containing mostly null bytes and some header information. The content shows:\n",
       "\n",
       "- \"Bud1\" header\n",
       "- \"DSDB\" marker\n",
       "- Various null bytes and special characters\n",
       "- Memory addresses or offset markers (@)\n",
       "\n",
       "This is **not a relevant project file** - it appears to be either:\n",
       "1. A binary executable or compiled file\n",
       "2. A corrupted text file\n",
       "3. A database file or cache\n",
       "4. Some kind of system/temporary file\n",
       "\n",
       "**Result:** \"\"\n",
       "\n",
       "This file should be ignored as it contains no readable source code, documentation, or configuration information that would be useful for understanding the project.), (slidev.iml, \"\"\n",
       "\n",
       "This file appears to be an IntelliJ IDEA module configuration file (.iml), which is IDE-specific configuration rather than actual project source code. These files are typically generated automatically by the IDE and don't contain relevant project logic or content that would be useful for understanding the actual codebase.)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:32:26.566264Z",
     "start_time": "2025-10-16T14:31:51.546928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val readme = runBlocking {\n",
    "    executor.execute(prompt(\"write-readme\") {\n",
    "        system {\n",
    "            +\"Write a meaningfull README.md for the summarisation of the project\"\n",
    "        }\n",
    "        user {\n",
    "            xml {\n",
    "                summarised.forEach { (name, summary) ->\n",
    "                    tag(name) { +summary }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }, AnthropicModels.Sonnet_4_5).single().content\n",
    "}\n",
    "readme"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# Koog AI Agents - Project Documentation Generator\n",
       "\n",
       "[![Kotlin](https://img.shields.io/badge/Kotlin-2.2.20--Beta2-blue.svg)](https://kotlinlang.org/)\n",
       "[![Koog](https://img.shields.io/badge/Koog-0.5.0-purple.svg)](https://github.com/koog-ai/koog)\n",
       "[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)\n",
       "\n",
       "> 🤖 A meta-demonstration of AI-powered documentation generation using Kotlin and LLMs. This project documents itself by analyzing its own codebase using the Koog AI Agents library.\n",
       "\n",
       "## 🎯 What Is This?\n",
       "\n",
       "This is both a **working tool** and an **educational resource** that demonstrates how to build production-ready AI agents in Kotlin. It showcases:\n",
       "\n",
       "- **Automated Documentation Generation**: Analyzes codebases and generates comprehensive README files\n",
       "- **Multi-Provider LLM Integration**: Works with both cloud APIs (Anthropic Claude) and local models (Ollama)\n",
       "- **Production-Ready Patterns**: Async processing, error handling, and token budget management\n",
       "- **Educational Content**: Complete presentation materials explaining LLMs, DSLs, and prompt engineering\n",
       "\n",
       "### The Meta Twist 🎭\n",
       "\n",
       "This README was generated by the very system it documents - demonstrating the power and practical utility of AI-assisted development workflows.\n",
       "\n",
       "## 🏗️ Architecture\n",
       "\n",
       "```mermaid\n",
       "graph LR\n",
       "    A[Project Files] --> B[File Scanner]\n",
       "    B --> C[Parallel Summarizer]\n",
       "    C --> D[LLM Provider]\n",
       "    D --> E[Summary Aggregator]\n",
       "    E --> F[README Generator]\n",
       "```\n",
       "\n",
       "**Key Components:**\n",
       "\n",
       "1. **File Scanner**: Recursively scans directories, filtering relevant files\n",
       "2. **Parallel Summarizer**: Uses Kotlin coroutines to process multiple files concurrently\n",
       "3. **LLM Provider**: Abstract interface supporting multiple AI providers (Claude, Ollama, etc.)\n",
       "4. **Summary Aggregator**: Synthesizes individual summaries into coherent documentation\n",
       "5. **Prompt Engineering**: Structured XML-tagged prompts for precise LLM guidance\n",
       "\n",
       "## 🚀 Quick Start\n",
       "\n",
       "### Prerequisites\n",
       "\n",
       "```bash\n",
       "# Install Node.js dependencies (for presentation)\n",
       "npm install\n",
       "\n",
       "# Set up API keys\n",
       "export ANTHROPIC_API_KEY=\"your-api-key-here\"\n",
       "\n",
       "# (Optional) Install Ollama for local LLM\n",
       "brew install ollama\n",
       "ollama pull llama3.2\n",
       "```\n",
       "\n",
       "### Running the Documentation Generator\n",
       "\n",
       "```kotlin\n",
       "// The Jupyter notebook (PromptChain.ipynb) contains the full implementation\n",
       "// Run it cell-by-cell to see the documentation generation in action\n",
       "\n",
       "// Key configuration\n",
       "val projectPath = Paths.get(\".\")\n",
       "val outputFile = projectPath.resolve(\"README.md\")\n",
       "val tokenBudget = 200_000  // Stay within Claude's context window\n",
       "```\n",
       "\n",
       "### Viewing the Presentation\n",
       "\n",
       "```bash\n",
       "# Development mode with hot reload\n",
       "npm run dev\n",
       "\n",
       "# Build static site\n",
       "npm run build\n",
       "\n",
       "# Export to PDF\n",
       "npm run export\n",
       "```\n",
       "\n",
       "## 💡 Key Features\n",
       "\n",
       "### 1. **Elegant Kotlin DSL**\n",
       "\n",
       "```kotlin\n",
       "prompt {\n",
       "    system {\n",
       "        +\"You are an expert code analyst\"\n",
       "        +\"Focus on architecture and key functionalities\"\n",
       "    }\n",
       "    \n",
       "    user {\n",
       "        tag(\"file\", \"name\" to filename) {\n",
       "            +fileContent\n",
       "        }\n",
       "        tag(\"instructions\") {\n",
       "            +\"Summarize this file's purpose and implementation\"\n",
       "        }\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "### 2. **Async Parallel Processing**\n",
       "\n",
       "```kotlin\n",
       "val summaries = relevantFiles.map { file ->\n",
       "    async(Dispatchers.IO) {\n",
       "        summarizeFile(file, client)\n",
       "    }\n",
       "}.awaitAll()\n",
       "```\n",
       "\n",
       "### 3. **Multi-Provider Support**\n",
       "\n",
       "```kotlin\n",
       "// Use Claude for production\n",
       "val claude = anthropicClient(\n",
       "    apiKey = System.getenv(\"ANTHROPIC_API_KEY\"),\n",
       "    model = \"claude-sonnet-4.5\"\n",
       ")\n",
       "\n",
       "// Use Ollama for local development\n",
       "val local = ollamaClient(\n",
       "    baseUrl = \"http://localhost:11434\",\n",
       "    model = \"llama3.2\"\n",
       ")\n",
       "```\n",
       "\n",
       "### 4. **Token Budget Awareness**\n",
       "\n",
       "```kotlin\n",
       "// Automatically manages context window limits\n",
       "tag(\"budget\", \"token_budget\" to \"200000\") {\n",
       "    +\"Stay within this token limit for the complete README\"\n",
       "}\n",
       "```\n",
       "\n",
       "## 📚 What You'll Learn\n",
       "\n",
       "### From the Notebook (`PromptChain.ipynb`)\n",
       "- Setting up multi-provider LLM clients in Kotlin\n",
       "- Building type-safe prompt DSLs with lambdas and receivers\n",
       "- Managing async/parallel workflows with coroutines\n",
       "- Handling large-scale file processing with token budgets\n",
       "- Practical prompt engineering techniques\n",
       "\n",
       "### From the Presentation (`slides.md`)\n",
       "- **LLM Fundamentals**: Tokenization, context windows, parameter tuning\n",
       "- **Koog Framework**: Architecture and design principles\n",
       "- **Kotlin DSL Design**: Extension functions, builder patterns, type-safe builders\n",
       "- **Tool Calling**: Building AI agents that can execute functions\n",
       "- **Ktor Integration**: Server-sent events for streaming responses\n",
       "- **Hands-on Exercises**: Interactive coding challenges\n",
       "\n",
       "## 🛠️ Technology Stack\n",
       "\n",
       "| Component | Technology | Purpose |\n",
       "|-----------|-----------|---------|\n",
       "| **Language** | Kotlin 2.2.20-Beta2 | Type-safe, expressive JVM language |\n",
       "| **AI Framework** | Koog Agents JVM 0.5.0 | LLM integration and agent orchestration |\n",
       "| **LLM Provider** | Anthropic Claude Sonnet 4.5 | Production-grade language model |\n",
       "| **Local LLM** | Ollama (Llama 3.2) | Privacy-focused local inference |\n",
       "| **Async Runtime** | Kotlin Coroutines | Concurrent file processing |\n",
       "| **Presentation** | Slidev | Developer-friendly slide framework |\n",
       "| **Syntax Highlighting** | Shiki | Beautiful code presentation |\n",
       "\n",
       "## 📁 Project Structure\n",
       "\n",
       "```\n",
       ".\n",
       "├── PromptChain.ipynb       # Main implementation notebook\n",
       "├── slides.md               # Comprehensive presentation\n",
       "├── Chat2.ipynb            # Experimental examples\n",
       "├── slidev.config.ts       # Presentation configuration\n",
       "├── setup/\n",
       "│   └── main.ts           # Vue component setup\n",
       "├── package.json          # Node.js dependencies\n",
       "└── README.md            # This file (auto-generated!)\n",
       "```\n",
       "\n",
       "## 🎓 Educational Use Cases\n",
       "\n",
       "This project is ideal for:\n",
       "\n",
       "- **Workshops**: Teaching LLM integration in Kotlin\n",
       "- **Code Reviews**: Understanding DSL design patterns\n",
       "- **Onboarding**: Learning prompt engineering best practices\n",
       "- **Research**: Experimenting with different LLM providers\n",
       "- **Production**: Building real documentation automation tools\n",
       "\n",
       "## 🔧 Advanced Configuration\n",
       "\n",
       "### Custom Summarization Strategies\n",
       "\n",
       "```kotlin\n",
       "// Focus on security aspects\n",
       "prompt {\n",
       "    system { +\"Focus on security vulnerabilities and best practices\" }\n",
       "}\n",
       "\n",
       "// Generate API documentation\n",
       "prompt {\n",
       "    system { +\"Extract and document all public APIs and their usage\" }\n",
       "}\n",
       "\n",
       "// Analyze performance characteristics\n",
       "prompt {\n",
       "    system { +\"Identify performance bottlenecks and optimization opportunities\" }\n",
       "}\n",
       "```\n",
       "\n",
       "### Local-First Development\n",
       "\n",
       "```kotlin\n",
       "// Run completely offline with Ollama\n",
       "val localClient = ollamaClient(\n",
       "    baseUrl = \"http://localhost:11434\",\n",
       "    model = \"llama3.2\",\n",
       "    temperature = 0.7\n",
       ")\n",
       "\n",
       "// No API keys required, full privacy\n",
       "val summaries = generateDocumentation(localClient)\n",
       "```\n",
       "\n",
       "## 🌟 Why This Matters\n",
       "\n",
       "### For Developers\n",
       "- **Reduce Documentation Debt**: Automatically generate and update documentation\n",
       "- **Understand Codebases Faster**: Quick summaries of unfamiliar projects\n",
       "- **Learn Modern Patterns**: See production-ready Kotlin and LLM integration\n",
       "\n",
       "### For Teams\n",
       "- **Onboard New Members**: Generated docs help new developers understand architecture\n",
       "- **Maintain Knowledge**: Documentation stays in sync with code changes\n",
       "- **Standardize Docs**: Consistent documentation format across projects\n",
       "\n",
       "### For Education\n",
       "- **Practical Examples**: Real-world usage of LLMs beyond toy examples\n",
       "- **Design Patterns**: Learn Kotlin DSL design through working code\n",
       "- **Best Practices**: Prompt engineering techniques that actually work\n",
       "\n",
       "## 📊 Performance Characteristics\n",
       "\n",
       "- **Parallel Processing**: Processes multiple files concurrently using coroutines\n",
       "- **"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "2.2.20-Beta2",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
